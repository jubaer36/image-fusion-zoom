{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f6f6f24",
   "metadata": {},
   "source": [
    "# LRD Image Fusion Model Evaluation\n",
    "\n",
    "This notebook runs the LRD (Laplacian Re-Decomposition) image fusion model and saves the results to a dedicated folder. We'll use our virtual environment to ensure all dependencies are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# For evaluation metrics\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Import our evaluation module\n",
    "import fusion_evaluation as fe\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Check if we're running in the virtual environment\n",
    "import site\n",
    "print(f\"Using Python from: {sys.executable}\")\n",
    "print(f\"Site packages: {site.getsitepackages()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e898ab",
   "metadata": {},
   "source": [
    "## Import LRD Functions\n",
    "\n",
    "First, let's import the key functions from our LRD Image Fusion notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533da3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to dataset\n",
    "base_dataset_path = \"Medical_Image_Fusion_Methods/Havard-Medical-Image-Fusion-Datasets\"\n",
    "modality_pair = \"CT-MRI\"  # Can be changed to PET-MRI or SPECT-MRI\n",
    "\n",
    "def load_image_pair(img_path1, img_path2, resize=True, img_size=256):\n",
    "    \"\"\"\n",
    "    Load a pair of medical images from different modalities\n",
    "    \n",
    "    Args:\n",
    "        img_path1: Path to first image (e.g., CT)\n",
    "        img_path2: Path to second image (e.g., MRI)\n",
    "        resize: Whether to resize images\n",
    "        img_size: Target size for resizing\n",
    "        \n",
    "    Returns:\n",
    "        A tuple containing both images as numpy arrays\n",
    "    \"\"\"\n",
    "    # Read images\n",
    "    img1 = cv2.imread(img_path1, cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(img_path2, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Check if images were loaded successfully\n",
    "    if img1 is None or img2 is None:\n",
    "        raise ValueError(f\"Failed to load images: {img_path1} or {img_path2}\")\n",
    "    \n",
    "    # Resize if needed\n",
    "    if resize and (img1.shape[0] != img_size or img1.shape[1] != img_size):\n",
    "        img1 = cv2.resize(img1, (img_size, img_size))\n",
    "        img2 = cv2.resize(img2, (img_size, img_size))\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    img1 = img1 / 255.0\n",
    "    img2 = img2 / 255.0\n",
    "    \n",
    "    return img1, img2\n",
    "\n",
    "def get_image_pairs(dataset_path, modality_pair, count=None):\n",
    "    \"\"\"\n",
    "    Get paths to pairs of medical images\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Base path to dataset\n",
    "        modality_pair: Type of modality pair, e.g., 'CT-MRI', 'PET-MRI', 'SPECT-MRI'\n",
    "        count: Number of pairs to return (None for all)\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples containing paths to image pairs\n",
    "    \"\"\"\n",
    "    # Get full path to specific modality folder\n",
    "    modality_path = os.path.join(dataset_path, modality_pair)\n",
    "    \n",
    "    # Split modality names\n",
    "    modalities = modality_pair.split('-')\n",
    "    mod1 = modalities[0].lower()  # e.g., ct\n",
    "    mod2 = modalities[1].lower()  # e.g., mri\n",
    "    \n",
    "    # Get lists of image paths for each modality\n",
    "    mod1_paths = sorted(glob.glob(os.path.join(modality_path, f\"*_{mod1}.png\")))\n",
    "    mod2_paths = sorted(glob.glob(os.path.join(modality_path, f\"*_{mod2}.png\")))\n",
    "    \n",
    "    # Ensure same number of images for both modalities\n",
    "    assert len(mod1_paths) == len(mod2_paths), \"Number of images in both modalities should be the same\"\n",
    "    \n",
    "    # Create pairs of image paths\n",
    "    pairs = list(zip(mod1_paths, mod2_paths))\n",
    "    \n",
    "    # Limit number of pairs if specified\n",
    "    if count is not None:\n",
    "        pairs = pairs[:min(count, len(pairs))]\n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dbc428",
   "metadata": {},
   "source": [
    "## Implement the LRD Fusion Model\n",
    "\n",
    "Now, let's implement the key components of the LRD fusion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2747690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's implement the Gaussian and Laplacian pyramid construction\n",
    "\n",
    "def gaussian_pyramid(img, levels=4):\n",
    "    \"\"\"\n",
    "    Build a Gaussian pyramid for an image\n",
    "    \n",
    "    Args:\n",
    "        img: Input image as a numpy array\n",
    "        levels: Number of pyramid levels\n",
    "        \n",
    "    Returns:\n",
    "        List of Gaussian pyramid levels from highest to lowest resolution\n",
    "    \"\"\"\n",
    "    pyramid = [img.copy()]\n",
    "    \n",
    "    # Create pyramid levels by successive downsampling\n",
    "    for i in range(levels - 1):\n",
    "        # Apply Gaussian smoothing\n",
    "        smoothed = cv2.GaussianBlur(pyramid[-1], (5, 5), 0.5)\n",
    "        # Downsample by factor of 2\n",
    "        downsampled = smoothed[::2, ::2]\n",
    "        pyramid.append(downsampled)\n",
    "    \n",
    "    return pyramid\n",
    "\n",
    "def laplacian_pyramid(img, levels=4):\n",
    "    \"\"\"\n",
    "    Build a Laplacian pyramid for an image\n",
    "    \n",
    "    Args:\n",
    "        img: Input image as a numpy array\n",
    "        levels: Number of pyramid levels\n",
    "        \n",
    "    Returns:\n",
    "        List of Laplacian pyramid levels from highest to lowest resolution\n",
    "    \"\"\"\n",
    "    # Build Gaussian pyramid\n",
    "    gauss_pyramid = gaussian_pyramid(img, levels)\n",
    "    \n",
    "    # Build Laplacian pyramid\n",
    "    laplacian_levels = []\n",
    "    \n",
    "    for i in range(levels - 1):\n",
    "        # Get current and next Gaussian levels\n",
    "        current = gauss_pyramid[i]\n",
    "        next_level = gauss_pyramid[i + 1]\n",
    "        \n",
    "        # Upsample next level\n",
    "        upsampled = np.zeros(current.shape)\n",
    "        upsampled[::2, ::2] = next_level\n",
    "        # Smooth the upsampled image to approximate original Gaussian filtering\n",
    "        upsampled = cv2.GaussianBlur(upsampled, (5, 5), 0.5)\n",
    "        \n",
    "        # Compute Laplacian (difference between current level and upsampled next level)\n",
    "        laplacian = current - upsampled\n",
    "        laplacian_levels.append(laplacian)\n",
    "    \n",
    "    # Add the last Gaussian level (lowest resolution)\n",
    "    laplacian_levels.append(gauss_pyramid[-1])\n",
    "    \n",
    "    return laplacian_levels\n",
    "\n",
    "def reconstruct_from_laplacian(laplacian_pyramid):\n",
    "    \"\"\"\n",
    "    Reconstruct an image from its Laplacian pyramid\n",
    "    \n",
    "    Args:\n",
    "        laplacian_pyramid: List of Laplacian pyramid levels\n",
    "        \n",
    "    Returns:\n",
    "        Reconstructed image\n",
    "    \"\"\"\n",
    "    # Start with the lowest resolution level (coarsest)\n",
    "    reconstructed = laplacian_pyramid[-1].copy()\n",
    "    \n",
    "    # Iteratively add upsampled version and Laplacian residual\n",
    "    for i in range(len(laplacian_pyramid) - 2, -1, -1):\n",
    "        # Current Laplacian level\n",
    "        laplacian = laplacian_pyramid[i]\n",
    "        \n",
    "        # Upsample current reconstructed image\n",
    "        upsampled = np.zeros(laplacian.shape)\n",
    "        upsampled[::2, ::2] = reconstructed\n",
    "        upsampled = cv2.GaussianBlur(upsampled, (5, 5), 0.5)\n",
    "        \n",
    "        # Add Laplacian level\n",
    "        reconstructed = upsampled + laplacian\n",
    "    \n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04fcef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's implement the Laplacian Re-Decomposition and fusion rules\n",
    "\n",
    "def calculate_saliency(img, window_size=3):\n",
    "    \"\"\"\n",
    "    Calculate the saliency map of an image\n",
    "    \n",
    "    Args:\n",
    "        img: Input image as a numpy array\n",
    "        window_size: Size of the window for local variance calculation\n",
    "        \n",
    "    Returns:\n",
    "        Saliency map of the image\n",
    "    \"\"\"\n",
    "    # Pad image for edge handling\n",
    "    pad = window_size // 2\n",
    "    padded = np.pad(img, pad, mode='reflect')\n",
    "    \n",
    "    # Initialize saliency map\n",
    "    saliency = np.zeros_like(img)\n",
    "    \n",
    "    # Calculate local variance for each pixel\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Extract local window\n",
    "            window = padded[i:i+window_size, j:j+window_size]\n",
    "            # Calculate local variance\n",
    "            saliency[i, j] = np.var(window)\n",
    "    \n",
    "    return saliency\n",
    "\n",
    "def laplacian_re_decomposition(lap_level, num_channels=2):\n",
    "    \"\"\"\n",
    "    Apply re-decomposition on a Laplacian pyramid level\n",
    "    \n",
    "    Args:\n",
    "        lap_level: A level from the Laplacian pyramid\n",
    "        num_channels: Number of channels for re-decomposition\n",
    "        \n",
    "    Returns:\n",
    "        Re-decomposed Laplacian level\n",
    "    \"\"\"\n",
    "    # Apply abs to capture both positive and negative variations\n",
    "    abs_level = np.abs(lap_level)\n",
    "    \n",
    "    # Use standard deviation as a threshold for re-decomposition\n",
    "    threshold = np.std(abs_level)\n",
    "    \n",
    "    # Create re-decomposed channels based on threshold\n",
    "    re_decomposed = []\n",
    "    for i in range(num_channels):\n",
    "        # Each channel captures different intensity ranges\n",
    "        # Scale thresholds to create different channels\n",
    "        channel_threshold = threshold * (i+1) / num_channels\n",
    "        channel = np.where(abs_level >= channel_threshold, lap_level, 0)\n",
    "        re_decomposed.append(channel)\n",
    "    \n",
    "    return re_decomposed\n",
    "\n",
    "def fuse_laplacian_levels(lap_level1, lap_level2):\n",
    "    \"\"\"\n",
    "    Fuse two Laplacian pyramid levels using saliency-based weighting\n",
    "    \n",
    "    Args:\n",
    "        lap_level1: First Laplacian pyramid level\n",
    "        lap_level2: Second Laplacian pyramid level\n",
    "        \n",
    "    Returns:\n",
    "        Fused Laplacian level\n",
    "    \"\"\"\n",
    "    # Calculate saliency maps\n",
    "    saliency1 = calculate_saliency(lap_level1)\n",
    "    saliency2 = calculate_saliency(lap_level2)\n",
    "    \n",
    "    # Create weight maps based on saliency\n",
    "    # Add small epsilon to avoid division by zero\n",
    "    epsilon = 1e-10\n",
    "    weight1 = saliency1 / (saliency1 + saliency2 + epsilon)\n",
    "    weight2 = saliency2 / (saliency1 + saliency2 + epsilon)\n",
    "    \n",
    "    # Re-decompose Laplacian levels\n",
    "    redecomp1 = laplacian_re_decomposition(lap_level1)\n",
    "    redecomp2 = laplacian_re_decomposition(lap_level2)\n",
    "    \n",
    "    # Fuse re-decomposed channels\n",
    "    fused_channels = []\n",
    "    for ch1, ch2 in zip(redecomp1, redecomp2):\n",
    "        # Apply weighted fusion\n",
    "        fused_channel = weight1 * ch1 + weight2 * ch2\n",
    "        fused_channels.append(fused_channel)\n",
    "    \n",
    "    # Combine fused channels\n",
    "    # For each pixel, use the maximum value across all channels\n",
    "    fused_level = np.zeros_like(lap_level1)\n",
    "    for channel in fused_channels:\n",
    "        fused_level = np.maximum(fused_level, channel)\n",
    "    \n",
    "    return fused_level\n",
    "\n",
    "def lrd_fusion(img1, img2, levels=4):\n",
    "    \"\"\"\n",
    "    Perform image fusion using Laplacian Re-Decomposition\n",
    "    \n",
    "    Args:\n",
    "        img1: First input image\n",
    "        img2: Second input image\n",
    "        levels: Number of pyramid levels\n",
    "        \n",
    "    Returns:\n",
    "        Fused image\n",
    "    \"\"\"\n",
    "    # Build Laplacian pyramids for both images\n",
    "    lap_pyr1 = laplacian_pyramid(img1, levels)\n",
    "    lap_pyr2 = laplacian_pyramid(img2, levels)\n",
    "    \n",
    "    # Fuse each pyramid level\n",
    "    fused_pyramid = []\n",
    "    for i in range(levels):\n",
    "        # For the last level (lowest resolution), use average\n",
    "        if i == levels - 1:\n",
    "            fused_level = (lap_pyr1[i] + lap_pyr2[i]) / 2\n",
    "        else:\n",
    "            # Apply LRD fusion for higher levels\n",
    "            fused_level = fuse_laplacian_levels(lap_pyr1[i], lap_pyr2[i])\n",
    "        \n",
    "        fused_pyramid.append(fused_level)\n",
    "    \n",
    "    # Reconstruct fused image from pyramid\n",
    "    fused_img = reconstruct_from_laplacian(fused_pyramid)\n",
    "    \n",
    "    # Ensure pixel values are in valid range [0, 1]\n",
    "    fused_img = np.clip(fused_img, 0, 1)\n",
    "    \n",
    "    return fused_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b716310b",
   "metadata": {},
   "source": [
    "## Get Dataset and Load Image Pairs\n",
    "\n",
    "Now, let's get the image pairs from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all image pairs\n",
    "image_pairs = get_image_pairs(base_dataset_path, modality_pair)\n",
    "print(f\"Found {len(image_pairs)} image pairs for {modality_pair}\")\n",
    "\n",
    "# Display a sample pair\n",
    "if image_pairs:\n",
    "    img1_path, img2_path = image_pairs[0]\n",
    "    img1, img2 = load_image_pair(img1_path, img2_path)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "    plt.title(os.path.basename(img1_path))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    plt.title(os.path.basename(img2_path))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No image pairs found. Please check the dataset path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3332386",
   "metadata": {},
   "source": [
    "## Process Image Pairs with LRD Fusion\n",
    "\n",
    "Now, let's apply the LRD fusion to our image pairs and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67563968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of image pairs to process (None for all)\n",
    "max_pairs = 5\n",
    "\n",
    "# Process image pairs\n",
    "if image_pairs:\n",
    "    # Limit the number of pairs if specified\n",
    "    if max_pairs is not None:\n",
    "        pairs_to_process = image_pairs[:min(max_pairs, len(image_pairs))]\n",
    "    else:\n",
    "        pairs_to_process = image_pairs\n",
    "    \n",
    "    # Initialize results storage\n",
    "    results = []\n",
    "    \n",
    "    # Process each pair\n",
    "    for idx, (img1_path, img2_path) in enumerate(tqdm(pairs_to_process, desc=\"Processing\")):\n",
    "        # Load images\n",
    "        img1, img2 = load_image_pair(img1_path, img2_path)\n",
    "        \n",
    "        # Apply LRD fusion\n",
    "        start_time = time.time()\n",
    "        fused_img = lrd_fusion(img1, img2, levels=4)\n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Save the result using our evaluation module\n",
    "        output_path = fe.save_fusion_result(fused_img, img1_path, img2_path, \"LRD\")\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = fe.evaluate_fusion(fused_img, img1, img2)\n",
    "        metrics['time'] = execution_time\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'img1': os.path.basename(img1_path),\n",
    "            'img2': os.path.basename(img2_path),\n",
    "            'output': output_path,\n",
    "            **metrics\n",
    "        })\n",
    "        \n",
    "        # Display the first result\n",
    "        if idx == 0:\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            \n",
    "            # First input image\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(img1, cmap='gray')\n",
    "            plt.title(os.path.basename(img1_path))\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Second input image\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(img2, cmap='gray')\n",
    "            plt.title(os.path.basename(img2_path))\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Fused result\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(fused_img, cmap='gray')\n",
    "            plt.title('LRD Fusion Result')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Add metrics as text\n",
    "            metrics_text = (\n",
    "                f\"PSNR: {metrics['psnr']:.2f} dB\\n\"\n",
    "                f\"SSIM: {metrics['ssim']:.4f}\\n\"\n",
    "                f\"Time: {execution_time:.3f} s\"\n",
    "            )\n",
    "            plt.figtext(0.5, 0.01, metrics_text, ha='center', fontsize=12, \n",
    "                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_psnr = np.mean([r['psnr'] for r in results])\n",
    "    avg_ssim = np.mean([r['ssim'] for r in results])\n",
    "    avg_time = np.mean([r['time'] for r in results])\n",
    "    \n",
    "    print(f\"\\nProcessed {len(results)} image pairs\")\n",
    "    print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "    print(f\"Average SSIM: {avg_ssim:.4f}\")\n",
    "    print(f\"Average execution time: {avg_time:.3f} seconds per image pair\")\n",
    "    print(f\"Results saved to fused_images/LRD/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d228feab",
   "metadata": {},
   "source": [
    "## Summary of Results\n",
    "\n",
    "We have successfully applied the LRD fusion method to the medical image pairs and saved the results to the `fused_images/LRD/` folder. These results can be compared with other fusion methods to evaluate the performance of different approaches.\n",
    "\n",
    "Here's what we've accomplished:\n",
    "1. Created a Python virtual environment for running image fusion models\n",
    "2. Set up a folder structure for organizing fused images\n",
    "3. Implemented the LRD fusion method from our previous notebook\n",
    "4. Applied the fusion to multiple image pairs\n",
    "5. Saved the results and calculated performance metrics\n",
    "\n",
    "The LRD method is computationally efficient and doesn't require deep learning techniques, making it suitable for environments with limited computational resources."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
