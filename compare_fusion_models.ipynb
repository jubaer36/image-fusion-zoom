{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b25c14",
   "metadata": {},
   "source": [
    "# Medical Image Fusion Models Comparison\n",
    "\n",
    "This notebook compares three different medical image fusion models:\n",
    "1. LRD (Laplacian Re-Decomposition)\n",
    "2. NSST-PAPCNN (Non-Subsampled Shearlet Transform with Parameter-Adaptive Pulse Coupled Neural Network)\n",
    "3. U2Fusion (Unified Unsupervised Image Fusion)\n",
    "\n",
    "We will compare their performance using quantitative metrics and visual assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69fe428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "# For evaluation metrics\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Import our evaluation module\n",
    "import fusion_evaluation as fe\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Check if we're running in the virtual environment\n",
    "import site\n",
    "print(f\"Using Python from: {sys.executable}\")\n",
    "print(f\"Site packages: {site.getsitepackages()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4dd271",
   "metadata": {},
   "source": [
    "## Helper Functions for Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e084c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to dataset\n",
    "base_dataset_path = \"Medical_Image_Fusion_Methods/Havard-Medical-Image-Fusion-Datasets\"\n",
    "\n",
    "def load_image_pair(img_path1, img_path2, resize=True, img_size=256):\n",
    "    \"\"\"\n",
    "    Load a pair of medical images from different modalities\n",
    "    \n",
    "    Args:\n",
    "        img_path1: Path to first image (e.g., CT)\n",
    "        img_path2: Path to second image (e.g., MRI)\n",
    "        resize: Whether to resize images\n",
    "        img_size: Target size for resizing\n",
    "        \n",
    "    Returns:\n",
    "        A tuple containing both images as numpy arrays\n",
    "    \"\"\"\n",
    "    # Read images\n",
    "    img1 = cv2.imread(img_path1, cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(img_path2, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Check if images were loaded successfully\n",
    "    if img1 is None or img2 is None:\n",
    "        raise ValueError(f\"Failed to load images: {img_path1} or {img_path2}\")\n",
    "    \n",
    "    # Resize if needed\n",
    "    if resize and (img1.shape[0] != img_size or img1.shape[1] != img_size):\n",
    "        img1 = cv2.resize(img1, (img_size, img_size))\n",
    "        img2 = cv2.resize(img2, (img_size, img_size))\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    img1 = img1 / 255.0\n",
    "    img2 = img2 / 255.0\n",
    "    \n",
    "    return img1, img2\n",
    "\n",
    "def get_image_pairs(dataset_path, modality_pair, count=None):\n",
    "    \"\"\"\n",
    "    Get paths to pairs of medical images\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Base path to dataset\n",
    "        modality_pair: Type of modality pair, e.g., 'CT-MRI', 'PET-MRI', 'SPECT-MRI'\n",
    "        count: Number of pairs to return (None for all)\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples containing paths to image pairs\n",
    "    \"\"\"\n",
    "    # Get full path to specific modality folder\n",
    "    modality_path = os.path.join(dataset_path, modality_pair)\n",
    "    \n",
    "    # Split modality names\n",
    "    modalities = modality_pair.split('-')\n",
    "    mod1 = modalities[0].lower()  # e.g., ct\n",
    "    mod2 = modalities[1].lower()  # e.g., mri\n",
    "    \n",
    "    # Get lists of image paths for each modality\n",
    "    mod1_paths = sorted(glob.glob(os.path.join(modality_path, f\"*_{mod1}.png\")))\n",
    "    mod2_paths = sorted(glob.glob(os.path.join(modality_path, f\"*_{mod2}.png\")))\n",
    "    \n",
    "    # Ensure same number of images for both modalities\n",
    "    assert len(mod1_paths) == len(mod2_paths), \"Number of images in both modalities should be the same\"\n",
    "    \n",
    "    # Create pairs of image paths\n",
    "    pairs = list(zip(mod1_paths, mod2_paths))\n",
    "    \n",
    "    # Limit number of pairs if specified\n",
    "    if count is not None:\n",
    "        pairs = pairs[:min(count, len(pairs))]\n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf65f5",
   "metadata": {},
   "source": [
    "## Load Fused Results from Each Model\n",
    "\n",
    "First, let's check what results are available from each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417fa824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_results():\n",
    "    \"\"\"\n",
    "    Get available fusion results from all models\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with available results for each model\n",
    "    \"\"\"\n",
    "    # Models to check\n",
    "    models = ['LRD', 'NSST_PAPCNN', 'U2Fusion']\n",
    "    \n",
    "    # Dictionary to store available results\n",
    "    available_results = {}\n",
    "    \n",
    "    # Check each model\n",
    "    for model in models:\n",
    "        model_dir = os.path.join('fused_images', model)\n",
    "        if os.path.exists(model_dir):\n",
    "            # Get list of result files\n",
    "            result_files = sorted(glob.glob(os.path.join(model_dir, '*.png')))\n",
    "            available_results[model] = result_files\n",
    "            print(f\"{model}: {len(result_files)} results available\")\n",
    "        else:\n",
    "            print(f\"{model}: Directory not found\")\n",
    "    \n",
    "    return available_results\n",
    "\n",
    "# Get available results\n",
    "available_results = get_available_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d468f9e9",
   "metadata": {},
   "source": [
    "## Find Common Image Pairs Processed by All Models\n",
    "\n",
    "For fair comparison, we'll identify image pairs that have been processed by all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_pairs(available_results):\n",
    "    \"\"\"\n",
    "    Find common image pairs processed by all models\n",
    "    \n",
    "    Args:\n",
    "        available_results: Dictionary with available results for each model\n",
    "        \n",
    "    Returns:\n",
    "        List of common pair names\n",
    "    \"\"\"\n",
    "    # Get models with available results\n",
    "    models_with_results = [model for model, results in available_results.items() if results]\n",
    "    \n",
    "    # If no models have results, return empty list\n",
    "    if not models_with_results:\n",
    "        return []\n",
    "    \n",
    "    # Extract pair names from first model\n",
    "    first_model = models_with_results[0]\n",
    "    first_model_pairs = [os.path.basename(path).split('.')[0] for path in available_results[first_model]]\n",
    "    \n",
    "    # Find common pairs across all models\n",
    "    common_pairs = set(first_model_pairs)\n",
    "    for model in models_with_results[1:]:\n",
    "        model_pairs = [os.path.basename(path).split('.')[0] for path in available_results[model]]\n",
    "        common_pairs &= set(model_pairs)\n",
    "    \n",
    "    return sorted(list(common_pairs))\n",
    "\n",
    "# Find common pairs\n",
    "common_pairs = find_common_pairs(available_results)\n",
    "print(f\"Found {len(common_pairs)} common image pairs processed by all models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50fe9d4",
   "metadata": {},
   "source": [
    "## Load Source Images and Fusion Results\n",
    "\n",
    "Now, let's load the source images and fusion results for common pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_modality_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Extract modality names from paired filenames\n",
    "    \n",
    "    Args:\n",
    "        filename: Paired filename (e.g., \"1_ct_1_mri\")\n",
    "        \n",
    "    Returns:\n",
    "        Tuple with modality names and pair ID\n",
    "    \"\"\"\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) == 4:  # Format: {id}_{mod1}_{id}_{mod2}\n",
    "        mod1 = parts[1].upper()\n",
    "        mod2 = parts[3].upper()\n",
    "        pair_id = f\"{parts[0]}_{parts[2]}\"\n",
    "        return mod1, mod2, pair_id\n",
    "    return None, None, None\n",
    "\n",
    "def get_source_images(pair_name, modality_pair=\"CT-MRI\"):\n",
    "    \"\"\"\n",
    "    Get source images for a pair name\n",
    "    \n",
    "    Args:\n",
    "        pair_name: Name of the image pair\n",
    "        modality_pair: Type of modality pair\n",
    "        \n",
    "    Returns:\n",
    "        Tuple with source images and their paths\n",
    "    \"\"\"\n",
    "    # Extract modalities from pair name\n",
    "    mod1, mod2, pair_id = extract_modality_from_filename(pair_name)\n",
    "    \n",
    "    # If extraction failed, use the default modality pair\n",
    "    if mod1 is None:\n",
    "        mod1, mod2 = modality_pair.split('-')\n",
    "    \n",
    "    # Construct paths to source images\n",
    "    modality_path = os.path.join(base_dataset_path, f\"{mod1}-{mod2}\")\n",
    "    \n",
    "    # Look for matching files\n",
    "    mod1_files = glob.glob(os.path.join(modality_path, f\"*_{mod1.lower()}.png\"))\n",
    "    mod2_files = glob.glob(os.path.join(modality_path, f\"*_{mod2.lower()}.png\"))\n",
    "    \n",
    "    # Try to find a matching pair based on the pair_name\n",
    "    img1_path = None\n",
    "    img2_path = None\n",
    "    \n",
    "    if pair_id:\n",
    "        # Try to find by pair ID\n",
    "        for file in mod1_files:\n",
    "            if pair_id.split('_')[0] in os.path.basename(file):\n",
    "                img1_path = file\n",
    "                break\n",
    "        \n",
    "        for file in mod2_files:\n",
    "            if pair_id.split('_')[1] in os.path.basename(file):\n",
    "                img2_path = file\n",
    "                break\n",
    "    \n",
    "    # If no specific match found, just use the first pair\n",
    "    if img1_path is None or img2_path is None:\n",
    "        if mod1_files and mod2_files:\n",
    "            img1_path = mod1_files[0]\n",
    "            img2_path = mod2_files[0]\n",
    "    \n",
    "    # If paths were found, load the images\n",
    "    if img1_path and img2_path:\n",
    "        img1, img2 = load_image_pair(img1_path, img2_path)\n",
    "        return img1, img2, img1_path, img2_path\n",
    "    \n",
    "    return None, None, None, None\n",
    "\n",
    "def load_all_results(pair_name, available_results):\n",
    "    \"\"\"\n",
    "    Load fusion results for all models for a given pair\n",
    "    \n",
    "    Args:\n",
    "        pair_name: Name of the image pair\n",
    "        available_results: Dictionary with available results for each model\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with fused images for each model\n",
    "    \"\"\"\n",
    "    # Dictionary to store fused images\n",
    "    fused_images = {}\n",
    "    \n",
    "    # Load results for each model\n",
    "    for model, results in available_results.items():\n",
    "        for result_path in results:\n",
    "            if pair_name in os.path.basename(result_path):\n",
    "                # Load fused image\n",
    "                fused_img = cv2.imread(result_path, cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "                fused_images[model] = fused_img\n",
    "                break\n",
    "    \n",
    "    return fused_images\n",
    "\n",
    "# Show an example of loaded source images and fusion results\n",
    "if common_pairs:\n",
    "    example_pair = common_pairs[0]\n",
    "    print(f\"Example pair: {example_pair}\")\n",
    "    \n",
    "    # Load source images\n",
    "    img1, img2, img1_path, img2_path = get_source_images(example_pair)\n",
    "    \n",
    "    # Load fusion results\n",
    "    fused_images = load_all_results(example_pair, available_results)\n",
    "    \n",
    "    if img1 is not None and img2 is not None and fused_images:\n",
    "        # Display source images and fusion results\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Source images\n",
    "        plt.subplot(2, 3, 1)\n",
    "        plt.imshow(img1, cmap='gray')\n",
    "        plt.title(f\"Source 1: {os.path.basename(img1_path)}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 3, 2)\n",
    "        plt.imshow(img2, cmap='gray')\n",
    "        plt.title(f\"Source 2: {os.path.basename(img2_path)}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Fusion results\n",
    "        for i, (model, fused_img) in enumerate(fused_images.items()):\n",
    "            plt.subplot(2, 3, i+3)\n",
    "            plt.imshow(fused_img, cmap='gray')\n",
    "            plt.title(f\"Fused: {model}\")\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Failed to load source images or fusion results.\")\n",
    "else:\n",
    "    print(\"No common pairs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b14154f",
   "metadata": {},
   "source": [
    "## Quantitative Comparison of Models\n",
    "\n",
    "Now, let's perform a quantitative comparison of all models using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e603c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_quantitatively(common_pairs, available_results):\n",
    "    \"\"\"\n",
    "    Compare models quantitatively using various metrics\n",
    "    \n",
    "    Args:\n",
    "        common_pairs: List of common pair names\n",
    "        available_results: Dictionary with available results for each model\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with metrics for each model and pair\n",
    "    \"\"\"\n",
    "    # List to store results\n",
    "    results = []\n",
    "    \n",
    "    # Models to evaluate\n",
    "    models = list(available_results.keys())\n",
    "    \n",
    "    # Evaluate each pair\n",
    "    for pair_name in tqdm(common_pairs, desc=\"Evaluating\"):\n",
    "        # Load source images\n",
    "        img1, img2, img1_path, img2_path = get_source_images(pair_name)\n",
    "        \n",
    "        # Skip if source images couldn't be loaded\n",
    "        if img1 is None or img2 is None:\n",
    "            continue\n",
    "        \n",
    "        # Load fusion results\n",
    "        fused_images = load_all_results(pair_name, available_results)\n",
    "        \n",
    "        # Calculate metrics for each model\n",
    "        for model, fused_img in fused_images.items():\n",
    "            # Calculate metrics\n",
    "            metrics = fe.evaluate_fusion(fused_img, img1, img2)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'pair': pair_name,\n",
    "                'model': model,\n",
    "                'psnr': metrics['psnr'],\n",
    "                'ssim': metrics['ssim']\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "# Compare models quantitatively\n",
    "if common_pairs:\n",
    "    df_results = compare_models_quantitatively(common_pairs, available_results)\n",
    "    \n",
    "    if not df_results.empty:\n",
    "        # Display results\n",
    "        print(\"\\nMetrics for each model and pair:\")\n",
    "        print(df_results)\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        summary = df_results.groupby('model').agg(['mean', 'std', 'min', 'max'])\n",
    "        print(\"\\nSummary statistics:\")\n",
    "        print(summary)\n",
    "        \n",
    "        # Plot results\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # PSNR comparison\n",
    "        plt.subplot(2, 2, 1)\n",
    "        sns.boxplot(x='model', y='psnr', data=df_results)\n",
    "        plt.title('PSNR Distribution')\n",
    "        plt.xlabel('Model')\n",
    "        plt.ylabel('PSNR (dB)')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # SSIM comparison\n",
    "        plt.subplot(2, 2, 2)\n",
    "        sns.boxplot(x='model', y='ssim', data=df_results)\n",
    "        plt.title('SSIM Distribution')\n",
    "        plt.xlabel('Model')\n",
    "        plt.ylabel('SSIM')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Barplot for average PSNR\n",
    "        plt.subplot(2, 2, 3)\n",
    "        avg_psnr = df_results.groupby('model')['psnr'].mean()\n",
    "        std_psnr = df_results.groupby('model')['psnr'].std()\n",
    "        avg_psnr.plot(kind='bar', yerr=std_psnr, capsize=4, rot=0)\n",
    "        plt.title('Average PSNR')\n",
    "        plt.xlabel('Model')\n",
    "        plt.ylabel('PSNR (dB)')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Barplot for average SSIM\n",
    "        plt.subplot(2, 2, 4)\n",
    "        avg_ssim = df_results.groupby('model')['ssim'].mean()\n",
    "        std_ssim = df_results.groupby('model')['ssim'].std()\n",
    "        avg_ssim.plot(kind='bar', yerr=std_ssim, capsize=4, rot=0)\n",
    "        plt.title('Average SSIM')\n",
    "        plt.xlabel('Model')\n",
    "        plt.ylabel('SSIM')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('fused_images/model_comparison_detailed.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"Saved detailed comparison chart to fused_images/model_comparison_detailed.png\")\n",
    "        \n",
    "        # Save results to CSV\n",
    "        df_results.to_csv('fused_images/model_comparison_metrics.csv', index=False)\n",
    "        print(\"Saved metrics to fused_images/model_comparison_metrics.csv\")\n",
    "    else:\n",
    "        print(\"No results to compare.\")\n",
    "else:\n",
    "    print(\"No common pairs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a9122d",
   "metadata": {},
   "source": [
    "## Visual Comparison of Models\n",
    "\n",
    "Let's create a function to visually compare the fusion results from all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_comparison(common_pairs, available_results, num_examples=3):\n",
    "    \"\"\"\n",
    "    Create a visual comparison of fusion results from all models\n",
    "    \n",
    "    Args:\n",
    "        common_pairs: List of common pair names\n",
    "        available_results: Dictionary with available results for each model\n",
    "        num_examples: Number of example pairs to show\n",
    "    \"\"\"\n",
    "    # Limit number of examples\n",
    "    examples = common_pairs[:min(num_examples, len(common_pairs))]\n",
    "    \n",
    "    # Get models with results\n",
    "    models = list(available_results.keys())\n",
    "    \n",
    "    # Number of columns for display (source images + models)\n",
    "    num_cols = 2 + len(models)\n",
    "    \n",
    "    # Create figure for visual comparison\n",
    "    plt.figure(figsize=(20, 5 * num_examples))\n",
    "    \n",
    "    # For each example pair\n",
    "    for i, pair_name in enumerate(examples):\n",
    "        # Load source images\n",
    "        img1, img2, img1_path, img2_path = get_source_images(pair_name)\n",
    "        \n",
    "        # Skip if source images couldn't be loaded\n",
    "        if img1 is None or img2 is None:\n",
    "            continue\n",
    "        \n",
    "        # Load fusion results\n",
    "        fused_images = load_all_results(pair_name, available_results)\n",
    "        \n",
    "        # Display source images\n",
    "        plt.subplot(num_examples, num_cols, i * num_cols + 1)\n",
    "        plt.imshow(img1, cmap='gray')\n",
    "        plt.title(f\"Source 1: {os.path.basename(img1_path)}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(num_examples, num_cols, i * num_cols + 2)\n",
    "        plt.imshow(img2, cmap='gray')\n",
    "        plt.title(f\"Source 2: {os.path.basename(img2_path)}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Display fusion results for each model\n",
    "        for j, model in enumerate(models):\n",
    "            if model in fused_images:\n",
    "                plt.subplot(num_examples, num_cols, i * num_cols + j + 3)\n",
    "                plt.imshow(fused_images[model], cmap='gray')\n",
    "                \n",
    "                # Calculate metrics\n",
    "                metrics = fe.evaluate_fusion(fused_images[model], img1, img2)\n",
    "                plt.title(f\"{model}\\nPSNR: {metrics['psnr']:.2f} dB, SSIM: {metrics['ssim']:.4f}\")\n",
    "                plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fused_images/visual_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Saved visual comparison to fused_images/visual_comparison.png\")\n",
    "\n",
    "# Perform visual comparison\n",
    "if common_pairs:\n",
    "    visual_comparison(common_pairs, available_results, num_examples=3)\n",
    "else:\n",
    "    print(\"No common pairs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e0c69",
   "metadata": {},
   "source": [
    "## Comparison of Computation Time\n",
    "\n",
    "Let's compare the computation time of each model by running them on the same image pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed3d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_computation_time(img1, img2, num_runs=5):\n",
    "    \"\"\"\n",
    "    Compare computation time of different fusion models\n",
    "    \n",
    "    Args:\n",
    "        img1: First source image\n",
    "        img2: Second source image\n",
    "        num_runs: Number of runs for each model\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with average computation time for each model\n",
    "    \"\"\"\n",
    "    # Import fusion models\n",
    "    from run_lrd_fusion import lrd_fusion\n",
    "    from run_nsst_papcnn_fusion import nsst_papcnn_fusion\n",
    "    from run_u2fusion_fusion import u2fusion\n",
    "    \n",
    "    # Dictionary to store computation times\n",
    "    computation_times = {}\n",
    "    \n",
    "    # LRD Fusion\n",
    "    times = []\n",
    "    for _ in range(num_runs):\n",
    "        start_time = time.time()\n",
    "        _ = lrd_fusion(img1, img2)\n",
    "        times.append(time.time() - start_time)\n",
    "    computation_times['LRD'] = np.mean(times)\n",
    "    \n",
    "    # NSST-PAPCNN Fusion\n",
    "    times = []\n",
    "    for _ in range(num_runs):\n",
    "        start_time = time.time()\n",
    "        _ = nsst_papcnn_fusion(img1, img2)\n",
    "        times.append(time.time() - start_time)\n",
    "    computation_times['NSST_PAPCNN'] = np.mean(times)\n",
    "    \n",
    "    # U2Fusion\n",
    "    times = []\n",
    "    for _ in range(num_runs):\n",
    "        start_time = time.time()\n",
    "        _ = u2fusion(img1, img2)\n",
    "        times.append(time.time() - start_time)\n",
    "    computation_times['U2Fusion'] = np.mean(times)\n",
    "    \n",
    "    return computation_times\n",
    "\n",
    "# Compare computation time on a sample image pair\n",
    "if common_pairs:\n",
    "    sample_pair = common_pairs[0]\n",
    "    img1, img2, _, _ = get_source_images(sample_pair)\n",
    "    \n",
    "    if img1 is not None and img2 is not None:\n",
    "        print(\"Comparing computation time...\")\n",
    "        computation_times = compare_computation_time(img1, img2, num_runs=3)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\nAverage computation time:\")\n",
    "        for model, time_taken in computation_times.items():\n",
    "            print(f\"{model}: {time_taken:.4f} seconds\")\n",
    "        \n",
    "        # Plot results\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(computation_times.keys(), computation_times.values())\n",
    "        plt.xlabel('Model')\n",
    "        plt.ylabel('Computation Time (seconds)')\n",
    "        plt.title('Average Computation Time Comparison')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('fused_images/computation_time_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"Saved computation time comparison to fused_images/computation_time_comparison.png\")\n",
    "    else:\n",
    "        print(\"Failed to load source images.\")\n",
    "else:\n",
    "    print(\"No common pairs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b3ed5c",
   "metadata": {},
   "source": [
    "## Detailed Analysis of Best Model\n",
    "\n",
    "Based on the quantitative metrics and visual comparison, let's identify and analyze the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_best_model(df_results):\n",
    "    \"\"\"\n",
    "    Identify the best-performing model based on metrics\n",
    "    \n",
    "    Args:\n",
    "        df_results: DataFrame with metrics for each model and pair\n",
    "        \n",
    "    Returns:\n",
    "        Name of the best model\n",
    "    \"\"\"\n",
    "    # Calculate average metrics for each model\n",
    "    avg_metrics = df_results.groupby('model').mean()\n",
    "    \n",
    "    # Normalize metrics to [0, 1] range for fair comparison\n",
    "    normalized_psnr = (avg_metrics['psnr'] - avg_metrics['psnr'].min()) / (avg_metrics['psnr'].max() - avg_metrics['psnr'].min())\n",
    "    normalized_ssim = (avg_metrics['ssim'] - avg_metrics['ssim'].min()) / (avg_metrics['ssim'].max() - avg_metrics['ssim'].min())\n",
    "    \n",
    "    # Combined score (equal weight for PSNR and SSIM)\n",
    "    combined_score = normalized_psnr * 0.5 + normalized_ssim * 0.5\n",
    "    \n",
    "    # Get best model\n",
    "    best_model = combined_score.idxmax()\n",
    "    \n",
    "    # Print scores for all models\n",
    "    print(\"Normalized Scores (higher is better):\")\n",
    "    print(\"\\nPSNR:\")\n",
    "    for model, score in normalized_psnr.items():\n",
    "        print(f\"{model}: {score:.4f}\")\n",
    "    \n",
    "    print(\"\\nSSIM:\")\n",
    "    for model, score in normalized_ssim.items():\n",
    "        print(f\"{model}: {score:.4f}\")\n",
    "    \n",
    "    print(\"\\nCombined Score:\")\n",
    "    for model, score in combined_score.items():\n",
    "        print(f\"{model}: {score:.4f}\")\n",
    "    \n",
    "    print(f\"\\nBest Model: {best_model}\")\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Identify the best model\n",
    "if 'df_results' in locals() and not df_results.empty:\n",
    "    best_model = identify_best_model(df_results)\n",
    "else:\n",
    "    print(\"No results to analyze.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b9a5b",
   "metadata": {},
   "source": [
    "## Summary and Conclusion\n",
    "\n",
    "In this notebook, we have compared three different medical image fusion models:\n",
    "\n",
    "1. LRD (Laplacian Re-Decomposition)\n",
    "2. NSST-PAPCNN (Non-Subsampled Shearlet Transform with Parameter-Adaptive Pulse Coupled Neural Network)\n",
    "3. U2Fusion (Unified Unsupervised Image Fusion)\n",
    "\n",
    "We evaluated their performance using quantitative metrics (PSNR, SSIM) and visual assessment. We also compared their computation time.\n",
    "\n",
    "Based on our analysis, we have identified the best-performing model, considering both the quality of the fused images and the computational efficiency.\n",
    "\n",
    "The results of this comparison provide valuable insights for choosing the most appropriate fusion model for medical image fusion applications, depending on specific requirements such as fusion quality, computation time, and the type of medical images being processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4263d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export summary of findings\n",
    "if 'df_results' in locals() and not df_results.empty and 'computation_times' in locals():\n",
    "    # Create a comprehensive summary\n",
    "    summary_dict = {\n",
    "        'Model': [],\n",
    "        'Average PSNR': [],\n",
    "        'Average SSIM': [],\n",
    "        'Computation Time': []\n",
    "    }\n",
    "    \n",
    "    # Add data for each model\n",
    "    for model in df_results['model'].unique():\n",
    "        summary_dict['Model'].append(model)\n",
    "        summary_dict['Average PSNR'].append(df_results[df_results['model'] == model]['psnr'].mean())\n",
    "        summary_dict['Average SSIM'].append(df_results[df_results['model'] == model]['ssim'].mean())\n",
    "        summary_dict['Computation Time'].append(computation_times.get(model, float('nan')))\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    summary_df = pd.DataFrame(summary_dict)\n",
    "    summary_df.to_csv('fused_images/model_comparison_summary.csv', index=False)\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\nSummary of Findings:\")\n",
    "    print(summary_df)\n",
    "    print(\"\\nSaved summary to fused_images/model_comparison_summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
