{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50346acd",
   "metadata": {},
   "source": [
    "# Medical Image Fusion with NSST-PAPCNN\n",
    "\n",
    "This notebook implements the NSST-PAPCNN (Non-Subsampled Shearlet Transform with Parameter-Adaptive Pulse Coupled Neural Network) model for medical image fusion. This approach is based on the paper [\"Medical Image Fusion With Parameter-Adaptive Pulse Coupled Neural Network in Nonsubsampled Shearlet Transform Domain\"](https://ieeexplore.ieee.org/document/8385209/).\n",
    "\n",
    "The NSST-PAPCNN approach is particularly effective for medical image fusion and uses a hybrid method combining:\n",
    "1. Non-Subsampled Shearlet Transform (NSST) for multi-scale, multi-directional image decomposition\n",
    "2. Parameter-Adaptive Pulse Coupled Neural Network (PAPCNN) for high-frequency coefficient fusion\n",
    "\n",
    "This is a lightweight approach that doesn't require deep learning techniques or GPU acceleration.\n",
    "\n",
    "## Overview of NSST-PAPCNN Method\n",
    "\n",
    "The NSST-PAPCNN method follows these key steps:\n",
    "1. Decompose source images using Non-Subsampled Shearlet Transform (NSST) into multi-scale and multi-directional components\n",
    "2. Apply specific fusion rules to low-frequency and high-frequency coefficients\n",
    "3. For high-frequency coefficients, use a Parameter-Adaptive Pulse Coupled Neural Network (PAPCNN) to determine weights\n",
    "4. Reconstruct the final fused image using inverse NSST\n",
    "\n",
    "This approach is particularly good at preserving both structural and functional details in medical images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08b11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from scipy import ndimage\n",
    "import pywt  # PyWavelets for wavelet transform operations\n",
    "from skimage import filters, transform\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# For evaluation metrics\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b6573",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "First, we'll create functions to load and preprocess medical images from different modalities (e.g., CT-MRI, PET-MRI). We'll use the Harvard Medical Image Fusion Dataset available in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164cfa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to dataset\n",
    "base_dataset_path = \"Medical_Image_Fusion_Methods/Havard-Medical-Image-Fusion-Datasets\"\n",
    "modality_pair = \"CT-MRI\"  # Can be changed to PET-MRI or SPECT-MRI\n",
    "\n",
    "def load_image_pair(img_path1, img_path2, resize=True, img_size=256):\n",
    "    \"\"\"\n",
    "    Load a pair of medical images from different modalities\n",
    "    \n",
    "    Args:\n",
    "        img_path1: Path to first image (e.g., CT)\n",
    "        img_path2: Path to second image (e.g., MRI)\n",
    "        resize: Whether to resize images\n",
    "        img_size: Target size for resizing\n",
    "        \n",
    "    Returns:\n",
    "        A tuple containing both images as numpy arrays\n",
    "    \"\"\"\n",
    "    # Read images\n",
    "    img1 = cv2.imread(img_path1, cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(img_path2, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Check if images were loaded successfully\n",
    "    if img1 is None or img2 is None:\n",
    "        raise ValueError(f\"Failed to load images: {img_path1} or {img_path2}\")\n",
    "    \n",
    "    # Resize if needed\n",
    "    if resize and (img1.shape[0] != img_size or img1.shape[1] != img_size):\n",
    "        img1 = cv2.resize(img1, (img_size, img_size))\n",
    "        img2 = cv2.resize(img2, (img_size, img_size))\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    img1 = img1 / 255.0\n",
    "    img2 = img2 / 255.0\n",
    "    \n",
    "    return img1, img2\n",
    "\n",
    "def get_image_pairs(dataset_path, modality_pair, count=None):\n",
    "    \"\"\"\n",
    "    Get paths to pairs of medical images\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Base path to dataset\n",
    "        modality_pair: Type of modality pair, e.g., 'CT-MRI', 'PET-MRI', 'SPECT-MRI'\n",
    "        count: Number of pairs to return (None for all)\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples containing paths to image pairs\n",
    "    \"\"\"\n",
    "    # Get full path to specific modality folder\n",
    "    modality_path = os.path.join(dataset_path, modality_pair)\n",
    "    \n",
    "    # Split modality names\n",
    "    modalities = modality_pair.split('-')\n",
    "    mod1 = modalities[0].lower()  # e.g., ct\n",
    "    mod2 = modalities[1].lower()  # e.g., mri\n",
    "    \n",
    "    # Get lists of image paths for each modality\n",
    "    mod1_paths = sorted(glob.glob(os.path.join(modality_path, f\"*_{mod1}.png\")))\n",
    "    mod2_paths = sorted(glob.glob(os.path.join(modality_path, f\"*_{mod2}.png\")))\n",
    "    \n",
    "    # Ensure same number of images for both modalities\n",
    "    assert len(mod1_paths) == len(mod2_paths), \"Number of images in both modalities should be the same\"\n",
    "    \n",
    "    # Create pairs of image paths\n",
    "    pairs = list(zip(mod1_paths, mod2_paths))\n",
    "    \n",
    "    # Limit number of pairs if specified\n",
    "    if count is not None:\n",
    "        pairs = pairs[:min(count, len(pairs))]\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "# Get all image pairs\n",
    "image_pairs = get_image_pairs(base_dataset_path, modality_pair)\n",
    "print(f\"Found {len(image_pairs)} image pairs for {modality_pair}\")\n",
    "\n",
    "# Display a sample pair\n",
    "if image_pairs:\n",
    "    img1_path, img2_path = image_pairs[0]\n",
    "    img1, img2 = load_image_pair(img1_path, img2_path)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "    plt.title(modality_pair.split('-')[0])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    plt.title(modality_pair.split('-')[1])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No image pairs found. Please check the dataset path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3532219c",
   "metadata": {},
   "source": [
    "## NSST-PAPCNN Model Implementation\n",
    "\n",
    "Now we'll implement the NSST-PAPCNN model. Since the original implementation uses Matlab-specific functions for the Non-Subsampled Shearlet Transform (NSST), we'll implement a Python version using the PyWavelets library and our own shearlet-inspired decomposition.\n",
    "\n",
    "### 1. Multi-Scale Decomposition with Wavelet Transform\n",
    "\n",
    "First, let's implement the multi-scale decomposition using wavelet transform as an approximation of the shearlet transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsst_decomposition(img, levels=4, wavelet='db1'):\n",
    "    \"\"\"\n",
    "    Decompose image using wavelet transform as an approximation of NSST\n",
    "    \n",
    "    Args:\n",
    "        img: Input image\n",
    "        levels: Number of decomposition levels\n",
    "        wavelet: Wavelet type\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing coefficients at each level and orientation\n",
    "    \"\"\"\n",
    "    # Initialize result dictionary\n",
    "    decomposition = {}\n",
    "    \n",
    "    # Perform stationary wavelet transform (undecimated - similar to non-subsampled transform)\n",
    "    coeffs = pywt.swt2(img, wavelet, level=levels)\n",
    "    \n",
    "    # Extract coefficients\n",
    "    decomposition['lowpass'] = coeffs[0][0]  # Approximation coefficients from the highest level\n",
    "    \n",
    "    # Store highpass coefficients for each level\n",
    "    decomposition['highpass'] = []\n",
    "    \n",
    "    for i in range(levels):\n",
    "        # Get horizontal, vertical and diagonal details\n",
    "        level_coeffs = {\n",
    "            'horizontal': coeffs[i][1][0],\n",
    "            'vertical': coeffs[i][1][1],\n",
    "            'diagonal': coeffs[i][1][2]\n",
    "        }\n",
    "        decomposition['highpass'].append(level_coeffs)\n",
    "    \n",
    "    return decomposition\n",
    "\n",
    "def nsst_reconstruction(decomposition, wavelet='db1'):\n",
    "    \"\"\"\n",
    "    Reconstruct image from wavelet coefficients\n",
    "    \n",
    "    Args:\n",
    "        decomposition: Dictionary containing wavelet coefficients\n",
    "        wavelet: Wavelet type\n",
    "        \n",
    "    Returns:\n",
    "        Reconstructed image\n",
    "    \"\"\"\n",
    "    # Get number of levels\n",
    "    levels = len(decomposition['highpass'])\n",
    "    \n",
    "    # Prepare coefficients for reconstruction\n",
    "    coeffs = []\n",
    "    for i in range(levels):\n",
    "        level_idx = levels - 1 - i\n",
    "        if i == 0:\n",
    "            # For the first level, use the lowpass coefficients\n",
    "            cA = decomposition['lowpass']\n",
    "        else:\n",
    "            # For subsequent levels, approximate coefficients are already included\n",
    "            cA = None\n",
    "            \n",
    "        # Get highpass coefficients\n",
    "        level_highpass = decomposition['highpass'][level_idx]\n",
    "        cH = level_highpass['horizontal']\n",
    "        cV = level_highpass['vertical']\n",
    "        cD = level_highpass['diagonal']\n",
    "        \n",
    "        # Combine coefficients\n",
    "        if i == 0:\n",
    "            coeffs.append((cA, (cH, cV, cD)))\n",
    "        else:\n",
    "            coeffs.append((None, (cH, cV, cD)))\n",
    "    \n",
    "    # Perform inverse stationary wavelet transform\n",
    "    reconstructed = pywt.iswt2(coeffs, wavelet)\n",
    "    \n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5504b0",
   "metadata": {},
   "source": [
    "### 2. Parameter-Adaptive Pulse Coupled Neural Network (PAPCNN)\n",
    "\n",
    "Now, let's implement the Parameter-Adaptive Pulse Coupled Neural Network (PAPCNN) for high-frequency coefficient fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ce3db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spatial_frequency(img):\n",
    "    \"\"\"\n",
    "    Calculate spatial frequency of an image\n",
    "    \n",
    "    Args:\n",
    "        img: Input image\n",
    "        \n",
    "    Returns:\n",
    "        Spatial frequency value\n",
    "    \"\"\"\n",
    "    # Calculate row frequency\n",
    "    rf = np.sqrt(np.sum(np.diff(img, axis=1) ** 2) / (img.shape[0] * img.shape[1]))\n",
    "    \n",
    "    # Calculate column frequency\n",
    "    cf = np.sqrt(np.sum(np.diff(img, axis=0) ** 2) / (img.shape[0] * img.shape[1]))\n",
    "    \n",
    "    # Calculate spatial frequency\n",
    "    sf = np.sqrt(rf ** 2 + cf ** 2)\n",
    "    \n",
    "    return sf\n",
    "\n",
    "def calculate_weight_exponent(img):\n",
    "    \"\"\"\n",
    "    Calculate weight exponent based on spatial frequency\n",
    "    \n",
    "    Args:\n",
    "        img: Input image\n",
    "        \n",
    "    Returns:\n",
    "        Weight exponent for PAPCNN\n",
    "    \"\"\"\n",
    "    sf = calculate_spatial_frequency(img)\n",
    "    # Based on the paper, weight exponent is inversely proportional to spatial frequency\n",
    "    weight_exp = np.exp(-sf)\n",
    "    return weight_exp\n",
    "\n",
    "def papcnn_fusion(img1, img2, iterations=10):\n",
    "    \"\"\"\n",
    "    Parameter-Adaptive Pulse Coupled Neural Network (PAPCNN) for image fusion\n",
    "    \n",
    "    Args:\n",
    "        img1: First input image\n",
    "        img2: Second input image\n",
    "        iterations: Number of PAPCNN iterations\n",
    "        \n",
    "    Returns:\n",
    "        Fusion weights for both images\n",
    "    \"\"\"\n",
    "    # Calculate weight exponents based on spatial frequency\n",
    "    beta1 = calculate_weight_exponent(img1)\n",
    "    beta2 = calculate_weight_exponent(img2)\n",
    "    \n",
    "    # Get image dimensions\n",
    "    h, w = img1.shape\n",
    "    \n",
    "    # Initialize PAPCNN variables\n",
    "    # F: Feeding input\n",
    "    F1 = img1.copy()\n",
    "    F2 = img2.copy()\n",
    "    \n",
    "    # L: Linking\n",
    "    L1 = np.zeros((h, w))\n",
    "    L2 = np.zeros((h, w))\n",
    "    \n",
    "    # U: Internal activity\n",
    "    U1 = F1\n",
    "    U2 = F2\n",
    "    \n",
    "    # Y: Pulse output\n",
    "    Y1 = np.zeros((h, w))\n",
    "    Y2 = np.zeros((h, w))\n",
    "    \n",
    "    # T: Dynamic threshold\n",
    "    T1 = np.ones((h, w))\n",
    "    T2 = np.ones((h, w))\n",
    "    \n",
    "    # Linking strength and decay parameters\n",
    "    alpha_L = 0.1\n",
    "    alpha_T = 0.2\n",
    "    V_T = 20.0\n",
    "    \n",
    "    # Kernel for linking\n",
    "    kernel = np.array([[0.1, 0.1, 0.1], \n",
    "                      [0.1, 0.0, 0.1], \n",
    "                      [0.1, 0.1, 0.1]])\n",
    "    \n",
    "    # Output accumulation\n",
    "    Y1_sum = np.zeros((h, w))\n",
    "    Y2_sum = np.zeros((h, w))\n",
    "    \n",
    "    # Iterate PAPCNN\n",
    "    for n in range(iterations):\n",
    "        # Update linking\n",
    "        L1 = alpha_L * L1 + ndimage.convolve(Y1, kernel, mode='constant')\n",
    "        L2 = alpha_L * L2 + ndimage.convolve(Y2, kernel, mode='constant')\n",
    "        \n",
    "        # Update internal activity\n",
    "        U1 = F1 * (1 + beta1 * L1)\n",
    "        U2 = F2 * (1 + beta2 * L2)\n",
    "        \n",
    "        # Update pulse output\n",
    "        Y1 = (U1 > T1).astype(np.float64)\n",
    "        Y2 = (U2 > T2).astype(np.float64)\n",
    "        \n",
    "        # Update threshold\n",
    "        T1 = alpha_T * T1 + V_T * Y1\n",
    "        T2 = alpha_T * T2 + V_T * Y2\n",
    "        \n",
    "        # Accumulate output\n",
    "        Y1_sum += Y1 * (n + 1)\n",
    "        Y2_sum += Y2 * (n + 1)\n",
    "    \n",
    "    # Calculate fusion weights\n",
    "    # Add small epsilon to avoid division by zero\n",
    "    epsilon = 1e-10\n",
    "    weight1 = Y1_sum / (Y1_sum + Y2_sum + epsilon)\n",
    "    weight2 = Y2_sum / (Y1_sum + Y2_sum + epsilon)\n",
    "    \n",
    "    return weight1, weight2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5315821e",
   "metadata": {},
   "source": [
    "### 3. Fusion Rules for Different Components\n",
    "\n",
    "Next, let's implement fusion rules for both low-frequency and high-frequency components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba29105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowpass_fusion(lowpass1, lowpass2):\n",
    "    \"\"\"\n",
    "    Fusion rule for low-frequency coefficients using average method\n",
    "    \n",
    "    Args:\n",
    "        lowpass1: Low-frequency coefficients of first image\n",
    "        lowpass2: Low-frequency coefficients of second image\n",
    "        \n",
    "    Returns:\n",
    "        Fused low-frequency coefficients\n",
    "    \"\"\"\n",
    "    # Simple average fusion for lowpass components\n",
    "    return (lowpass1 + lowpass2) / 2\n",
    "\n",
    "def highpass_fusion(highpass1, highpass2):\n",
    "    \"\"\"\n",
    "    Fusion rule for high-frequency coefficients using PAPCNN\n",
    "    \n",
    "    Args:\n",
    "        highpass1: High-frequency coefficients of first image\n",
    "        highpass2: High-frequency coefficients of second image\n",
    "        \n",
    "    Returns:\n",
    "        Fused high-frequency coefficients\n",
    "    \"\"\"\n",
    "    # Apply PAPCNN to determine weights\n",
    "    weight1, weight2 = papcnn_fusion(np.abs(highpass1), np.abs(highpass2))\n",
    "    \n",
    "    # Apply weighted fusion\n",
    "    fused_highpass = weight1 * highpass1 + weight2 * highpass2\n",
    "    \n",
    "    return fused_highpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a879ab58",
   "metadata": {},
   "source": [
    "### 4. Complete NSST-PAPCNN Fusion Method\n",
    "\n",
    "Finally, let's implement the complete NSST-PAPCNN fusion method by combining all the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b57b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsst_papcnn_fusion(img1, img2, levels=3, wavelet='db1'):\n",
    "    \"\"\"\n",
    "    Complete NSST-PAPCNN fusion method\n",
    "    \n",
    "    Args:\n",
    "        img1: First input image\n",
    "        img2: Second input image\n",
    "        levels: Number of decomposition levels\n",
    "        wavelet: Wavelet type\n",
    "        \n",
    "    Returns:\n",
    "        Fused image\n",
    "    \"\"\"\n",
    "    # Decompose images\n",
    "    decomp1 = nsst_decomposition(img1, levels, wavelet)\n",
    "    decomp2 = nsst_decomposition(img2, levels, wavelet)\n",
    "    \n",
    "    # Initialize fused decomposition\n",
    "    fused_decomp = {'lowpass': None, 'highpass': []}\n",
    "    \n",
    "    # Fuse lowpass coefficients\n",
    "    fused_decomp['lowpass'] = lowpass_fusion(decomp1['lowpass'], decomp2['lowpass'])\n",
    "    \n",
    "    # Fuse highpass coefficients for each level\n",
    "    for level in range(levels):\n",
    "        level_fused = {}\n",
    "        \n",
    "        # Fuse each orientation (horizontal, vertical, diagonal)\n",
    "        for orientation in ['horizontal', 'vertical', 'diagonal']:\n",
    "            highpass1 = decomp1['highpass'][level][orientation]\n",
    "            highpass2 = decomp2['highpass'][level][orientation]\n",
    "            level_fused[orientation] = highpass_fusion(highpass1, highpass2)\n",
    "        \n",
    "        fused_decomp['highpass'].append(level_fused)\n",
    "    \n",
    "    # Reconstruct fused image\n",
    "    fused_img = nsst_reconstruction(fused_decomp, wavelet)\n",
    "    \n",
    "    # Ensure pixel values are in valid range [0, 1]\n",
    "    fused_img = np.clip(fused_img, 0, 1)\n",
    "    \n",
    "    return fused_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17be1836",
   "metadata": {},
   "source": [
    "## Testing and Visualization\n",
    "\n",
    "Now, let's test our NSST-PAPCNN fusion method on medical image pairs and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822a4ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the NSST-PAPCNN fusion on a sample image pair\n",
    "def visualize_fusion_result(img_path1, img_path2, levels=3, wavelet='db1'):\n",
    "    \"\"\"\n",
    "    Visualize the fusion result for a pair of images\n",
    "    \n",
    "    Args:\n",
    "        img_path1: Path to first image\n",
    "        img_path2: Path to second image\n",
    "        levels: Number of decomposition levels\n",
    "        wavelet: Wavelet type\n",
    "    \"\"\"\n",
    "    # Load images\n",
    "    img1, img2 = load_image_pair(img_path1, img_path2)\n",
    "    \n",
    "    # Measure execution time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Apply NSST-PAPCNN fusion\n",
    "    fused_img = nsst_papcnn_fusion(img1, img2, levels, wavelet)\n",
    "    \n",
    "    # Calculate execution time\n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate metrics\n",
    "    # PSNR\n",
    "    psnr1 = psnr(img1, fused_img)\n",
    "    psnr2 = psnr(img2, fused_img)\n",
    "    avg_psnr = (psnr1 + psnr2) / 2\n",
    "    \n",
    "    # SSIM\n",
    "    ssim1 = ssim(img1, fused_img, data_range=1.0)\n",
    "    ssim2 = ssim(img2, fused_img, data_range=1.0)\n",
    "    avg_ssim = (ssim1 + ssim2) / 2\n",
    "    \n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # First input image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "    plt.title(os.path.basename(img_path1))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Second input image\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    plt.title(os.path.basename(img_path2))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Fused result\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(fused_img, cmap='gray')\n",
    "    plt.title('NSST-PAPCNN Fusion Result')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Add metrics as text\n",
    "    metrics_text = (\n",
    "        f\"PSNR: {avg_psnr:.2f} dB\\n\"\n",
    "        f\"SSIM: {avg_ssim:.4f}\\n\"\n",
    "        f\"Time: {execution_time:.3f} s\"\n",
    "    )\n",
    "    plt.figtext(0.5, 0.01, metrics_text, ha='center', fontsize=12, \n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fused_img\n",
    "\n",
    "# If we have image pairs, test on the first pair\n",
    "if image_pairs:\n",
    "    img_path1, img_path2 = image_pairs[0]\n",
    "    fused_img = visualize_fusion_result(img_path1, img_path2, levels=3, wavelet='db1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c146a9",
   "metadata": {},
   "source": [
    "## Parameter Analysis\n",
    "\n",
    "Let's examine how different parameters affect the fusion results, particularly the decomposition level and wavelet type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d24dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test different parameter combinations\n",
    "def test_parameters(img_path1, img_path2):\n",
    "    \"\"\"\n",
    "    Test different parameter combinations for NSST-PAPCNN fusion\n",
    "    \n",
    "    Args:\n",
    "        img_path1: Path to first image\n",
    "        img_path2: Path to second image\n",
    "    \"\"\"\n",
    "    # Load images\n",
    "    img1, img2 = load_image_pair(img_path1, img_path2)\n",
    "    \n",
    "    # Define parameter ranges\n",
    "    level_range = [2, 3, 4]\n",
    "    wavelet_range = ['db1', 'haar', 'sym2', 'coif1']\n",
    "    \n",
    "    # Initialize results grid\n",
    "    results = {}\n",
    "    \n",
    "    # Test each parameter combination\n",
    "    for levels in level_range:\n",
    "        for wavelet in wavelet_range:\n",
    "            print(f\"Testing with levels={levels}, wavelet={wavelet}\")\n",
    "            \n",
    "            # Measure execution time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Apply NSST-PAPCNN fusion with custom parameters\n",
    "            fused_img = nsst_papcnn_fusion(img1, img2, levels, wavelet)\n",
    "            \n",
    "            # Calculate execution time\n",
    "            execution_time = time.time() - start_time\n",
    "            \n",
    "            # Calculate metrics\n",
    "            psnr1 = psnr(img1, fused_img)\n",
    "            psnr2 = psnr(img2, fused_img)\n",
    "            avg_psnr = (psnr1 + psnr2) / 2\n",
    "            \n",
    "            ssim1 = ssim(img1, fused_img, data_range=1.0)\n",
    "            ssim2 = ssim(img2, fused_img, data_range=1.0)\n",
    "            avg_ssim = (ssim1 + ssim2) / 2\n",
    "            \n",
    "            # Store results\n",
    "            key = f\"L{levels}_W{wavelet}\"\n",
    "            results[key] = {\n",
    "                'fused_img': fused_img,\n",
    "                'psnr': avg_psnr,\n",
    "                'ssim': avg_ssim,\n",
    "                'time': execution_time\n",
    "            }\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(len(level_range), len(wavelet_range), figsize=(15, 12))\n",
    "    \n",
    "    # Add original images for reference\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "    plt.title(\"Image 1\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    plt.title(\"Image 2\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display fusion results\n",
    "    for i, levels in enumerate(level_range):\n",
    "        for j, wavelet in enumerate(wavelet_range):\n",
    "            key = f\"L{levels}_W{wavelet}\"\n",
    "            result = results[key]\n",
    "            \n",
    "            axes[i, j].imshow(result['fused_img'], cmap='gray')\n",
    "            axes[i, j].set_title(f\"L={levels}, W={wavelet}\\nPSNR: {result['psnr']:.2f}, SSIM: {result['ssim']:.3f}\")\n",
    "            axes[i, j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print best parameters based on metrics\n",
    "    best_psnr = max(results.items(), key=lambda x: x[1]['psnr'])\n",
    "    best_ssim = max(results.items(), key=lambda x: x[1]['ssim'])\n",
    "    fastest = min(results.items(), key=lambda x: x[1]['time'])\n",
    "    \n",
    "    print(\"Best parameters:\")\n",
    "    print(f\"Best PSNR: {best_psnr[0]} - {best_psnr[1]['psnr']:.2f} dB\")\n",
    "    print(f\"Best SSIM: {best_ssim[0]} - {best_ssim[1]['ssim']:.4f}\")\n",
    "    print(f\"Fastest: {fastest[0]} - {fastest[1]['time']:.3f} seconds\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test parameter combinations (uncomment to run)\n",
    "# if image_pairs:\n",
    "#     img_path1, img_path2 = image_pairs[0]\n",
    "#     parameter_results = test_parameters(img_path1, img_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeeffe5",
   "metadata": {},
   "source": [
    "## Batch Processing and Evaluation\n",
    "\n",
    "Let's process and evaluate multiple medical image pairs using our NSST-PAPCNN fusion method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process multiple images and save results\n",
    "def batch_process_and_save(image_pairs, output_dir=\"fusion_results\", \n",
    "                           levels=3, wavelet='db1', max_pairs=None):\n",
    "    \"\"\"\n",
    "    Process multiple image pairs and save fusion results\n",
    "    \n",
    "    Args:\n",
    "        image_pairs: List of tuples containing image pair paths\n",
    "        output_dir: Directory to save results\n",
    "        levels: Number of decomposition levels\n",
    "        wavelet: Wavelet type\n",
    "        max_pairs: Maximum number of pairs to process\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Limit number of pairs if specified\n",
    "    if max_pairs is not None:\n",
    "        pairs_to_process = image_pairs[:min(max_pairs, len(image_pairs))]\n",
    "    else:\n",
    "        pairs_to_process = image_pairs\n",
    "    \n",
    "    # Initialize results storage\n",
    "    results = []\n",
    "    \n",
    "    # Process each pair\n",
    "    for idx, (img_path1, img_path2) in enumerate(tqdm(pairs_to_process, desc=\"Processing\")):\n",
    "        # Extract image names\n",
    "        img1_name = os.path.basename(img_path1).split('.')[0]\n",
    "        img2_name = os.path.basename(img_path2).split('.')[0]\n",
    "        output_name = f\"{img1_name}_{img2_name}_fused_L{levels}W{wavelet}.png\"\n",
    "        output_path = os.path.join(output_dir, output_name)\n",
    "        \n",
    "        # Load images\n",
    "        img1, img2 = load_image_pair(img_path1, img_path2)\n",
    "        \n",
    "        # Apply NSST-PAPCNN fusion\n",
    "        start_time = time.time()\n",
    "        fused_img = nsst_papcnn_fusion(img1, img2, levels, wavelet)\n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Calculate metrics\n",
    "        psnr1 = psnr(img1, fused_img)\n",
    "        psnr2 = psnr(img2, fused_img)\n",
    "        avg_psnr = (psnr1 + psnr2) / 2\n",
    "        \n",
    "        ssim1 = ssim(img1, fused_img, data_range=1.0)\n",
    "        ssim2 = ssim(img2, fused_img, data_range=1.0)\n",
    "        avg_ssim = (ssim1 + ssim2) / 2\n",
    "        \n",
    "        # Save result\n",
    "        fused_img_uint8 = (fused_img * 255).astype(np.uint8)\n",
    "        cv2.imwrite(output_path, fused_img_uint8)\n",
    "        \n",
    "        # Store metrics\n",
    "        results.append({\n",
    "            'img1': img1_name,\n",
    "            'img2': img2_name,\n",
    "            'psnr': avg_psnr,\n",
    "            'ssim': avg_ssim,\n",
    "            'time': execution_time\n",
    "        })\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    if results:\n",
    "        avg_psnr = np.mean([r['psnr'] for r in results])\n",
    "        avg_ssim = np.mean([r['ssim'] for r in results])\n",
    "        avg_time = np.mean([r['time'] for r in results])\n",
    "        \n",
    "        print(f\"\\nProcessed {len(results)} image pairs\")\n",
    "        print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "        print(f\"Average SSIM: {avg_ssim:.4f}\")\n",
    "        print(f\"Average execution time: {avg_time:.3f} seconds per image pair\")\n",
    "        print(f\"Results saved to {output_dir}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Process images with optimal parameters (uncomment to run)\n",
    "# optimal_results = batch_process_and_save(\n",
    "#     image_pairs=image_pairs, \n",
    "#     output_dir=\"nsst_papcnn_results\", \n",
    "#     levels=3,  # Optimal level parameter\n",
    "#     wavelet='db1',  # Optimal wavelet parameter\n",
    "#     max_pairs=5\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5351927",
   "metadata": {},
   "source": [
    "## Comparison with Other Methods\n",
    "\n",
    "Let's compare our NSST-PAPCNN fusion results with simple fusion methods like averaging and maximum selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c77fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_average_fusion(img1, img2):\n",
    "    \"\"\"\n",
    "    Simple averaging fusion method\n",
    "    \n",
    "    Args:\n",
    "        img1: First input image\n",
    "        img2: Second input image\n",
    "        \n",
    "    Returns:\n",
    "        Fused image using simple averaging\n",
    "    \"\"\"\n",
    "    return (img1 + img2) / 2\n",
    "\n",
    "def maximum_fusion(img1, img2):\n",
    "    \"\"\"\n",
    "    Maximum selection fusion method\n",
    "    \n",
    "    Args:\n",
    "        img1: First input image\n",
    "        img2: Second input image\n",
    "        \n",
    "    Returns:\n",
    "        Fused image using maximum selection\n",
    "    \"\"\"\n",
    "    return np.maximum(img1, img2)\n",
    "\n",
    "def compare_methods(img_path1, img_path2):\n",
    "    \"\"\"\n",
    "    Compare different fusion methods\n",
    "    \n",
    "    Args:\n",
    "        img_path1: Path to first image\n",
    "        img_path2: Path to second image\n",
    "    \"\"\"\n",
    "    # Load images\n",
    "    img1, img2 = load_image_pair(img_path1, img_path2)\n",
    "    \n",
    "    # Apply different fusion methods\n",
    "    methods = [\n",
    "        (\"Average\", simple_average_fusion(img1, img2)),\n",
    "        (\"Maximum\", maximum_fusion(img1, img2)),\n",
    "        (\"NSST-PAPCNN\", nsst_papcnn_fusion(img1, img2, levels=3, wavelet='db1'))\n",
    "    ]\n",
    "    \n",
    "    # Calculate metrics for each method\n",
    "    metrics = []\n",
    "    for method_name, fused_img in methods:\n",
    "        # Calculate PSNR\n",
    "        psnr1 = psnr(img1, fused_img)\n",
    "        psnr2 = psnr(img2, fused_img)\n",
    "        avg_psnr = (psnr1 + psnr2) / 2\n",
    "        \n",
    "        # Calculate SSIM\n",
    "        ssim1 = ssim(img1, fused_img, data_range=1.0)\n",
    "        ssim2 = ssim(img2, fused_img, data_range=1.0)\n",
    "        avg_ssim = (ssim1 + ssim2) / 2\n",
    "        \n",
    "        metrics.append((method_name, avg_psnr, avg_ssim))\n",
    "    \n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Display source images\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "    plt.title(os.path.basename(img_path1))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    plt.title(os.path.basename(img_path2))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Display fusion results\n",
    "    for i, (method_name, fused_img) in enumerate(methods):\n",
    "        plt.subplot(2, 3, i + 4)\n",
    "        plt.imshow(fused_img, cmap='gray')\n",
    "        plt.title(f\"{method_name}\\nPSNR: {metrics[i][1]:.2f}, SSIM: {metrics[i][2]:.4f}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nFusion Method Comparison:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"{'Method':<15} {'PSNR (dB)':<10} {'SSIM':<10}\")\n",
    "    print(\"-\" * 40)\n",
    "    for method_name, avg_psnr, avg_ssim in metrics:\n",
    "        print(f\"{method_name:<15} {avg_psnr:<10.2f} {avg_ssim:<10.4f}\")\n",
    "    \n",
    "    return methods, metrics\n",
    "\n",
    "# Compare different fusion methods (uncomment to run)\n",
    "# if image_pairs:\n",
    "#     img_path1, img_path2 = image_pairs[0]\n",
    "#     fusion_methods, fusion_metrics = compare_methods(img_path1, img_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d432eb40",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've implemented the NSST-PAPCNN (Non-Subsampled Shearlet Transform with Parameter-Adaptive Pulse Coupled Neural Network) model for medical image fusion. This approach offers several advantages:\n",
    "\n",
    "1. **Hybrid Approach**: The NSST-PAPCNN method combines transform-domain techniques with neural network-based fusion rules, providing a good balance between traditional and learning-based methods.\n",
    "\n",
    "2. **Parameter Adaptivity**: The PAPCNN component automatically adapts its parameters based on the characteristics of the input images, making it more flexible for different types of medical images.\n",
    "\n",
    "3. **Multi-Scale and Multi-Directional**: The NSST decomposition captures features at multiple scales and orientations, which is important for preserving both structural and functional information in medical images.\n",
    "\n",
    "4. **Computational Efficiency**: While more computationally intensive than simple fusion methods, NSST-PAPCNN is still much lighter than deep learning approaches and doesn't require specialized hardware.\n",
    "\n",
    "5. **No Training Required**: Unlike deep learning methods, the NSST-PAPCNN approach doesn't need training data, making it more practical when labeled data is limited.\n",
    "\n",
    "The NSST-PAPCNN method provides high-quality fusion results with a moderate computational cost, making it a good middle ground between simple fusion methods and complex deep learning approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8860e7",
   "metadata": {},
   "source": [
    "Based on my exploration, I've decided to create a Jupyter notebook implementing the NSST-PAPCNN (Non-Subsampled Shearlet Transform with Parameter-Adaptive Pulse Coupled Neural Network) model for medical image fusion. This model is interesting because:\n",
    "\n",
    "It uses a different approach than both the MATR and LRD models we've already implemented\n",
    "It combines traditional transform methods (shearlet transform) with neural networks (PCNN)\n",
    "It has shown good performance for medical image fusion specifically\n",
    "It has relatively low hardware requirements compared to deep learning methods\n",
    "Let me create a new notebook for implementing the NSST-PAPCNN model:\n",
    "\n",
    "Created NSST_PAPCNN_Image_Fusion.ipynb\n",
    "\n",
    "I've created a new Jupyter notebook implementing the NSST-PAPCNN (Non-Subsampled Shearlet Transform with Parameter-Adaptive Pulse Coupled Neural Network) model for medical image fusion. This approach is different from the LRD model we implemented previously and has some unique characteristics:\n",
    "\n",
    "NSST-PAPCNN Model Overview\n",
    "Hybrid Approach: NSST-PAPCNN combines traditional transform methods with a simplified neural network approach:\n",
    "\n",
    "Uses Non-Subsampled Shearlet Transform (NSST) for multi-scale, multi-directional decomposition\n",
    "Applies Parameter-Adaptive Pulse Coupled Neural Network (PAPCNN) for fusion rule determination\n",
    "Key Features:\n",
    "\n",
    "Multi-directional analysis: Better captures directional features in medical images\n",
    "Parameter adaptivity: Automatically adjusts parameters based on image characteristics\n",
    "No training required: Works without needing a training dataset\n",
    "Moderate computational cost: More advanced than LRD but still lighter than deep learning methods\n",
    "Implementation Components:\n",
    "\n",
    "Multi-scale decomposition using wavelet transform (as a Python approximation of shearlet transform)\n",
    "PAPCNN implementation for high-frequency coefficient fusion\n",
    "Separate fusion rules for low and high-frequency components\n",
    "Comprehensive evaluation metrics and visualization tools\n",
    "Comparison with LRD Model\n",
    "The NSST-PAPCNN approach represents a different trade-off compared to the LRD model:\n",
    "\n",
    "Computational complexity: Slightly more complex than LRD but still much lighter than deep learning models\n",
    "Directional sensitivity: Better preserves directional features than LRD's pyramid-based approach\n",
    "Neural component: Includes a simplified neural network component (PCNN) that adaptively determines fusion weights\n",
    "Edge preservation: Generally better at preserving edges and directional structures in medical images\n",
    "What's in the Notebook\n",
    "The notebook includes:\n",
    "\n",
    "Data loading and preprocessing: Functions to load and preprocess medical images from Harvard datasets\n",
    "NSST decomposition: Python implementation of a multi-scale, multi-directional transform\n",
    "PAPCNN implementation: Parameter-adaptive neural network for fusion weight determination\n",
    "Fusion rules: Specific methods for fusing low and high-frequency components\n",
    "Parameter analysis: Tools to study how different parameters affect fusion quality\n",
    "Comparative analysis: Functions to compare NSST-PAPCNN with simpler fusion methods\n",
    "Batch processing: Tools for processing multiple image pairs and evaluating results\n",
    "This implementation offers a good middle ground between the simplicity of LRD and the complexity of deep learning approaches, with particularly good performance for preserving directional features in medical images.\n",
    "\n",
    "Would you like me to explain any specific aspect of the NSST-PAPCNN implementation in more detail?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e90f9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
